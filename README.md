This code implements a **Multilayer Perceptron (MLP)** neural network from scratch using NumPy, capable of handling both **classification** (via softmax/cross-entropy) and **regression** (linear output/MSE) tasks. It features customizable architecture (hidden layers/neurons), ReLU/sigmoid/tanh activations, mini-batch gradient descent with backpropagation, and training utilities like early stopping and loss tracking. The example demonstrates its use on synthetic datasets for both problem types, providing a compact yet functional deep learning implementation for educational or small-scale applications.
